{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg3RwOJZoM9t",
        "outputId": "61f45c27-cbdd-4554-dd21-1fea53c7614b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws1OgR-5MRpi"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGMMVkhEPL50",
        "outputId": "794a2990-5c40-404e-e878-2df78de9e0a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "NgrokTunnel: \"https://df5d-35-245-219-245.ngrok-free.app\" -> \"http://localhost:80\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"Your Token\")\n",
        "!nohup streamlit run app.py --server.port 80 &\n",
        "url = ngrok.connect(80)\n",
        "print(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzyP2X39PPIT"
      },
      "outputs": [],
      "source": [
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACCJRLpswgG5",
        "outputId": "82319b63-f617-467b-a534-9520983452b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "from csv import writer as wcsv, reader as rcsv\n",
        "csvfile = \"/content/drive/My Drive/Project/demo.csv\"\n",
        "List = [\"ID\", \"Type\", \"Plate Number\"]\n",
        "with open(csvfile, 'w') as csvfileobject:\n",
        "          csvwriter = wcsv(csvfileobject)\n",
        "          csvwriter.writerow(List)\n",
        "          csvfileobject.close()\n",
        "\n",
        "# Vehicle Classification\n",
        "\n",
        "# Import necessary packages\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os.path import splitext,basename\n",
        "from keras.models import model_from_json\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import glob\n",
        "\n",
        "# Create a new model instance\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Input, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "sys.path.insert(0,'/content/drive/My Drive/Project/')\n",
        "# from IPython import get_ipython\n",
        "# get_ipython().magic('reset -sf')\n",
        "import cv2\n",
        "import collections\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import pandas as pd\n",
        "import heapq\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "from tools import generate_detections as gdet\n",
        "from deep_sort import preprocessing\n",
        "from deep_sort import nn_matching\n",
        "from deep_sort.detection import Detection\n",
        "from deep_sort.tracker import Tracker\n",
        "\n",
        "# Initialize Tracker\n",
        "max_cosine_distance = 0.8\n",
        "nn_budget = None\n",
        "model_filename = '/content/drive/My Drive/Project/deep_sort/mars-small128.pb'\n",
        "encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
        "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
        "tracker = Tracker(metric, n_init = 0)\n",
        "\n",
        "# Initialize the videocapture object\n",
        "cap = cv2.VideoCapture('/content/drive/My Drive/Project/test1.mp4')\n",
        "outputVideoPath = \"output.avi\"\n",
        "input_size = 320\n",
        "\n",
        "# Detection confidence threshold\n",
        "confThreshold =0.2\n",
        "nmsThreshold= 0.2\n",
        "\n",
        "font_color = (0, 0, 255)\n",
        "font_size = 0.5\n",
        "font_thickness = 2\n",
        "\n",
        "# Store Coco Names in a list\n",
        "csvfile = \"/content/drive/My Drive/Project/demo.csv\"\n",
        "classesFile = \"/content/drive/My Drive/Project/coco.names\"\n",
        "classNames = open(classesFile).read().strip().split('\\n')\n",
        "# print(classNames)\n",
        "#print(len(classNames))\n",
        "\n",
        "# class index for our required detection classes\n",
        "required_class_index = [2, 3, 5, 7]\n",
        "\n",
        "detected_classNames = []\n",
        "\n",
        "## Model Files\n",
        "modelConfiguration = '/content/drive/My Drive/Project/yolov3-320.cfg'\n",
        "modelWeigheights = '/content/drive/My Drive/Project/yolov3-320.weights'\n",
        "\n",
        "# configure the network model\n",
        "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeigheights)\n",
        "\n",
        "# Configure the network backend\n",
        "\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "\n",
        "# Define random colour for each class\n",
        "# np.random.seed(42)\n",
        "# colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
        "\n",
        "def initializeVideoWriter(video_width, video_height, videoStream):\n",
        "    # Getting the fps of the source video\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    # initialize our video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    return cv2.VideoWriter(outputVideoPath, fourcc, fps,\n",
        "        (video_width, video_height), True)\n",
        "\n",
        "video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "writer = initializeVideoWriter(video_width, video_height, cap)\n",
        "\n",
        "\n",
        "# Function for finding the detected objects from the network output\n",
        "def postProcess(outputs,img):\n",
        "    # st.image(img)\n",
        "    height, width = img.shape[:2]\n",
        "    boxes = []\n",
        "    classIds = []\n",
        "    confidence_scores = []\n",
        "    confidence_s = []\n",
        "    detection = []\n",
        "    names = []\n",
        "    for output in outputs:\n",
        "        for det in output:\n",
        "            scores = det[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            confidence = scores[classId]\n",
        "            if classId in required_class_index:\n",
        "                if confidence > confThreshold:\n",
        "                    # print(classId)\n",
        "                    w,h = int(det[2]*width) , int(det[3]*height)\n",
        "                    x,y = int((det[0]*width)-w/2) , int((det[1]*height)-h/2)\n",
        "                    boxes.append([x,y,w,h])\n",
        "                    classIds.append(classId)\n",
        "                    confidence_scores.append(float(confidence))\n",
        "\n",
        "    # Apply Non-Max Suppression\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, confThreshold, nmsThreshold)\n",
        "\n",
        "    # print(\"Car = \",indices)\n",
        "    if len(indices)>0:\n",
        "        for i in indices.flatten():\n",
        "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
        "            # print(w,h)\n",
        "\n",
        "            # color = [int(c) for c in colors[classIds[i]]]\n",
        "            name = classNames[classIds[i]]\n",
        "            names.append([name])\n",
        "            detection.append([x, y, w, h])\n",
        "            conf_s = round(confidence_scores[i],4)\n",
        "            confidence_s.append([conf_s])\n",
        "            # color = (255,0,255)\n",
        "            # cv2.putText(img,f'{name} {int(confidence_scores[i]*100)}%',\n",
        "            #         (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "            # cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
        "            # roi = img[int(y):int(y+h), int(x):int(x+w)]\n",
        "            # from_static(roi)\n",
        "\n",
        "            # boxes_ids = tracker.update(detections)\n",
        "            # for box_id in boxes_ids:\n",
        "            #     x11, y11, x22, y22, id = box_id\n",
        "            #     id = int(id)\n",
        "            #     # w, h = int(x2 - x1), int(y2 - y1)\n",
        "            #     xc = int((x11 + x22) / 2)\n",
        "            #     yc = int((y11 + y22) / 2)\n",
        "            #     df = pd.read_csv(csvfile)\n",
        "            #     if id in df['ID'].values:\n",
        "            #       pass\n",
        "            #     else:\n",
        "            #         df.loc[len(df.index)] = [id, name, 1]\n",
        "            #     df.to_csv(csvfile, index=False)\n",
        "\n",
        "            #     cv2.putText(img,f'{id}',\n",
        "            #         (xc, yc-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "\n",
        "    features = encoder(img, detection)\n",
        "    # DeepSORT -> Storing all the required info in a list.\n",
        "    detections = [Detection(bbox, \"{}\".format(*score), cname, feature) for bbox, score, cname, feature in zip(detection, confidence_s, names, features)]\n",
        "\n",
        "    # print(detections)\n",
        "    #initialize color map\n",
        "    cmap = plt.get_cmap('tab20b')\n",
        "    colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
        "\n",
        "    # Call the tracker\n",
        "    tracker.predict()\n",
        "    tracker.update(detections)\n",
        "    # print(len(tracker.tracks))\n",
        "    for track in tracker.tracks:\n",
        "        # if not track.is_confirmed() or track.time_since_update > 1:\n",
        "        #     continue\n",
        "        bbox = track.to_tlbr()\n",
        "        class_name = track.get_class()[0]\n",
        "        color = colors[int(track.track_id) % len(colors)]\n",
        "        color = [i * 255 for i in color]\n",
        "        # cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 1)\n",
        "        # cv2.rectangle(img, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*40, int(bbox[1])), color, -1)\n",
        "        # cv2.putText(img, f'{class_name} {track.track_id}',(int(bbox[0]), int(bbox[1]-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255),1)\n",
        "        # print(f'{class_name} {track.track_id}')\n",
        "        w = abs(bbox[2] - bbox[0])\n",
        "        h = abs(bbox[3] - bbox[1])\n",
        "        # cv2_imshow(img)\n",
        "        if w>200 and h>200:\n",
        "            vehicleframe = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "            # print(int(bbox[1])-50 , int(bbox[3])+50 , int(bbox[0])-50 , int(bbox[2])+50)\n",
        "            flag = False\n",
        "            if (int(bbox[1])-50 > 0 and int(bbox[3])+50 > 0 and int(bbox[0])-50 > 0 and int(bbox[2])+50 > 0):\n",
        "                vehicleframe1 = img[int(bbox[1])-50:int(bbox[3])+50, int(bbox[0])-50:int(bbox[2])+50]\n",
        "                flag = True\n",
        "            else :\n",
        "                vehicleframe1 = vehicleframe\n",
        "            cv2.imwrite(\"vehicleframe.jpg\", vehicleframe)\n",
        "            cv2.imwrite(\"extvehicleframe.jpg\", vehicleframe1)\n",
        "            texttype=\"Vehicle Type : \"+ class_name\n",
        "            st.write(texttype)\n",
        "            st.image(\"vehicleframe.jpg\", width=500)\n",
        "            plate_number = \"Unable To Recognized\"\n",
        "            if class_name == \"motorbike\":\n",
        "                # print(\"bike\")\n",
        "                plate_number_img, nvf = bikelicenceplate(vehicleframe, vehicleframe1, flag)\n",
        "                st.write(\"[INFO] Extract NumberPlate using Method 1...\")\n",
        "                if plate_number_img is not None:\n",
        "                    st.image(\"lpoutput.jpg\")\n",
        "                    if len(segment_characters(plate_number_img)) > 0:\n",
        "                        plate_number = show_results2(plate_number_img)\n",
        "                else:\n",
        "                    st.write(\"[INFO] Extract NumberPlate using Method 2...\")\n",
        "                    if nvf == plate_number_img:\n",
        "                        plate_number_img = extractNumberPlate(vehicleframe)\n",
        "                    else:\n",
        "                        plate_number_img = extractNumberPlate(nvf)\n",
        "                    if plate_number_img is not None:\n",
        "                        st.image(\"lpoutput.jpg\")\n",
        "                        if len(segment_characters(plate_number_img)) > 0:\n",
        "                            plate_number = show_results2(plate_number_img)\n",
        "                    else:\n",
        "                        st.write(\"[INFO] Extract NumberPlate using Method 3...\")\n",
        "                        if nvf == plate_number_img:\n",
        "                            plate_number_img = extractNumberPlate2(vehicleframe)\n",
        "                        else:\n",
        "                            plate_number_img = extractNumberPlate2(nvf)\n",
        "                        if plate_number_img is not None:\n",
        "                            st.image(\"lpoutput.jpg\")\n",
        "                            if len(segment_characters(plate_number_img)) > 0:\n",
        "                                plate_number = show_results2(plate_number_img)\n",
        "            else:\n",
        "                plate_number_img, nvf = licenceplate(vehicleframe, vehicleframe1, flag)\n",
        "                st.write(\"[INFO] Extract NumberPlate using Method 1...\")\n",
        "                if plate_number_img is not None:\n",
        "                    st.image(\"lpoutput.jpg\")\n",
        "                    if len(segment_characters(plate_number_img)) > 0:\n",
        "                        plate_number = show_results2(plate_number_img)\n",
        "                else:\n",
        "                    st.write(\"[INFO] Extract NumberPlate using Method 2...\")\n",
        "                    if nvf == plate_number_img:\n",
        "                        plate_number_img = extractNumberPlate(vehicleframe)\n",
        "                    else:\n",
        "                        plate_number_img = extractNumberPlate(nvf)\n",
        "                    if plate_number_img is not None:\n",
        "                        st.image(\"lpoutput.jpg\")\n",
        "                        if len(segment_characters(plate_number_img)) > 0:\n",
        "                            plate_number = show_results2(plate_number_img)\n",
        "                    else:\n",
        "                        st.write(\"[INFO] Extract NumberPlate using Method 3...\")\n",
        "                        if nvf == plate_number_img:\n",
        "                            plate_number_img = extractNumberPlate2(vehicleframe)\n",
        "                        else:\n",
        "                            plate_number_img = extractNumberPlate2(nvf)\n",
        "                        if plate_number_img is not None:\n",
        "                            st.image(\"lpoutput.jpg\")\n",
        "                            if len(segment_characters(plate_number_img)) > 0:\n",
        "                                plate_number = show_results2(plate_number_img)\n",
        "\n",
        "            if plate_number != \"Unable To Recognized\":\n",
        "                textlp = \"Licence Plate Number is : \" + plate_number\n",
        "                st.write(textlp)\n",
        "            else:\n",
        "                st.write(plate_number)\n",
        "\n",
        "            df = pd.read_csv(csvfile)\n",
        "            id = track.track_id\n",
        "            if id in df['ID'].values:\n",
        "                if plate_number == \"Unable To Recognized\":\n",
        "                    continue\n",
        "                new_plate = plate_number\n",
        "                old_plate = df.loc[df['ID'] == id, 'Plate Number'].values[0]\n",
        "                df.loc[df['ID'] == id, 'Plate Number'] = f\"{old_plate}, {new_plate}\"\n",
        "            else:\n",
        "                new_entry = [id, class_name, plate_number]\n",
        "                df.loc[len(df.index)] = new_entry\n",
        "\n",
        "            df.to_csv(csvfile, index=False)\n",
        "\n",
        "def licenceplate(img, img2, flag):\n",
        "    input_size = 320\n",
        "\n",
        "    font_color = (0, 0, 255)\n",
        "    font_size = 0.5\n",
        "    font_thickness = 2\n",
        "    # Store Coco Names in a list\n",
        "    classesFiles = \"/content/drive/My Drive/Project/classes.names\"\n",
        "    classNames = open(classesFiles).read().strip().split('\\n')\n",
        "    # print(classNames)\n",
        "    # print(len(classNames))\n",
        "\n",
        "    ## Model Files\n",
        "    modelConfig = '/content/drive/My Drive/Project/darknet-yolov3.cfg'\n",
        "    modelW = '/content/drive/My Drive/Project/lapi.weights'\n",
        "\n",
        "    # configure the network model\n",
        "    net = cv2.dnn.readNetFromDarknet(modelConfig, modelW)\n",
        "\n",
        "    # Configure the network backend\n",
        "\n",
        "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "\n",
        "    if img is None:\n",
        "        st.write(\"Image Error\")\n",
        "        return\n",
        "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
        "\n",
        "    # Set the input of the network\n",
        "    net.setInput(blob)\n",
        "    layersNames = net.getLayerNames()\n",
        "    outputNames = [(layersNames[i - 1]) for i in net.getUnconnectedOutLayers()]\n",
        "    # Feed data to the network\n",
        "    outputs = net.forward(outputNames)\n",
        "\n",
        "    # Find the objects from the network output\n",
        "    # class index for our required detection classes\n",
        "    required_class_ind = [0]\n",
        "    # Detection confidence threshold\n",
        "    confThreshold = 0.2\n",
        "    nmsThreshold= 0.2\n",
        "    scoreThreshold = 0.2\n",
        "    # Define random colour for each class\n",
        "    np.random.seed(42)\n",
        "    colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
        "    height, width = img.shape[:2]\n",
        "    boxes = []\n",
        "    classIds = []\n",
        "    confidence_scores = []\n",
        "    detection = []\n",
        "    for output in outputs:\n",
        "        for det in output:\n",
        "            scores = det[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            confidence = scores[classId]\n",
        "            if classId in required_class_ind:\n",
        "                if confidence > confThreshold:\n",
        "                    w,h = int(det[2]*width) , int(det[3]*height)\n",
        "                    x,y = int((det[0]*width)-w/2) , int((det[1]*height)-h/2)\n",
        "                    boxes.append([x,y,w,h])\n",
        "                    classIds.append(classId)\n",
        "                    confidence_scores.append(float(confidence))\n",
        "\n",
        "    # Apply Non-Max Suppression\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, scoreThreshold, nmsThreshold)\n",
        "    # print(\"LP =\",indices)\n",
        "    if len(indices) > 0:\n",
        "        for i in indices.flatten():\n",
        "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
        "            # print(x,y,w,h)\n",
        "\n",
        "            color = [int(c) for c in colors[classIds[i]]]\n",
        "            name = classNames[classIds[i]]\n",
        "\n",
        "            # Draw classname and confidence score\n",
        "            # cv2.putText(img,f'{name.upper()} {int(confidence_scores[i]*100)}%',\n",
        "            #           (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "\n",
        "            # Draw bounding rectangle\n",
        "            # cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
        "            # detection.append([x, y, w, h, required_class_ind.index(classIds[i])])\n",
        "            # print(detection)\n",
        "            if w>120 and h>20:\n",
        "                roi = img[y:y+h, x:x+w]\n",
        "                cv2.imwrite(\"lpoutput.jpg\", roi)\n",
        "                if flag:\n",
        "                    nvf = img2[y:y+h+125, x:x+125+w]\n",
        "                    # cv2_imshow(nvf)\n",
        "                    cv2.imwrite(\"newlpoutput.jpg\", nvf)\n",
        "                else:\n",
        "                    nvf = img[y:y+h, x:x+w]\n",
        "                    cv2.imwrite(\"newlpoutput.jpg\", nvf)\n",
        "                return roi, nvf\n",
        "    return None, None\n",
        "\n",
        "def bikelicenceplate(img, img2, flag):\n",
        "    input_size = 416\n",
        "\n",
        "    font_color = (0, 0, 255)\n",
        "    font_size = 0.5\n",
        "    font_thickness = 2\n",
        "    # Store Coco Names in a list\n",
        "    classesFiles = \"/content/drive/My Drive/Project/classes.names\"\n",
        "    classNames = open(classesFiles).read().strip().split('\\n')\n",
        "    # print(classNames)\n",
        "    # print(len(classNames))\n",
        "\n",
        "    ## Model Files\n",
        "    modelConfig = '/content/drive/My Drive/Project/yolov3-custom.cfg'\n",
        "    modelW = '/content/drive/My Drive/Project/yolov3-custom_7000.weights'\n",
        "\n",
        "    # configure the network model\n",
        "    net = cv2.dnn.readNetFromDarknet(modelConfig, modelW)\n",
        "\n",
        "    # Configure the network backend\n",
        "\n",
        "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "\n",
        "    if img is None:\n",
        "        st.write(\"Image Error\")\n",
        "        return\n",
        "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
        "\n",
        "    # Set the input of the network\n",
        "    net.setInput(blob)\n",
        "    layersNames = net.getLayerNames()\n",
        "    outputNames = [(layersNames[i - 1]) for i in net.getUnconnectedOutLayers()]\n",
        "    # Feed data to the network\n",
        "    outputs = net.forward(outputNames)\n",
        "\n",
        "    # Find the objects from the network output\n",
        "    # class index for our required detection classes\n",
        "    required_class_ind = [1]\n",
        "    # Detection confidence threshold\n",
        "    confThreshold = 0.2\n",
        "    nmsThreshold= 0.2\n",
        "    scoreThreshold = 0.2\n",
        "    # Define random colour for each class\n",
        "    np.random.seed(42)\n",
        "    colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
        "    height, width = img.shape[:2]\n",
        "    boxes = []\n",
        "    classIds = []\n",
        "    confidence_scores = []\n",
        "    detection = []\n",
        "    for output in outputs:\n",
        "        for det in output:\n",
        "            scores = det[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            confidence = scores[classId]\n",
        "            if classId in required_class_ind:\n",
        "                if confidence > confThreshold:\n",
        "                    w,h = int(det[2]*width) , int(det[3]*height)\n",
        "                    x,y = int((det[0]*width)-w/2) , int((det[1]*height)-h/2)\n",
        "                    boxes.append([x,y,w,h])\n",
        "                    classIds.append(classId)\n",
        "                    confidence_scores.append(float(confidence))\n",
        "\n",
        "    # Apply Non-Max Suppression\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, scoreThreshold, nmsThreshold)\n",
        "    # print(\"LP =\",indices)\n",
        "    if len(indices) > 0:\n",
        "        for i in indices.flatten():\n",
        "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
        "            # print(x,y,w,h)\n",
        "\n",
        "            color = [int(c) for c in colors[0]]\n",
        "            name = classNames[0]\n",
        "\n",
        "            # Draw classname and confidence score\n",
        "            # cv2.putText(img,f'{name.upper()} {int(confidence_scores[i]*100)}%',\n",
        "            #           (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "\n",
        "            # Draw bounding rectangle\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
        "            # detection.append([x, y, w, h, required_class_ind.index(classIds[i])])\n",
        "            # print(detection)\n",
        "            # cv2_imshow(img)\n",
        "            if w>120 and h>20:\n",
        "                roi = img[y:y+h, x:x+w]\n",
        "                cv2.imwrite(\"lpoutput.jpg\", roi)\n",
        "                if flag:\n",
        "                    nvf = img2[y:y+h+125, x:x+125+w]\n",
        "                    # cv2_imshow(nvf)\n",
        "                    cv2.imwrite(\"newlpoutput.jpg\", nvf)\n",
        "                else:\n",
        "                    nvf = img[y:y+h, x:x+w]\n",
        "                    cv2.imwrite(\"newlpoutput.jpg\", nvf)\n",
        "                return roi, nvf\n",
        "    return None, None\n",
        "\n",
        "def extractNumberPlate(image_):\n",
        "    image = imutils.resize(image_, width=500)\n",
        "\n",
        "    # Determine scaling factors\n",
        "    scale_x = image_.shape[1] / image.shape[1]\n",
        "    scale_y = image_.shape[0] / image.shape[0]\n",
        "\n",
        "    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # RGB to Gray scale conversion\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Noise removal with iterative bilateral filter(removes noise while preserving edges)\n",
        "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
        "\n",
        "    # Find Edges of the grayscale image\n",
        "    edged = cv2.Canny(gray, 170, 200)\n",
        "\n",
        "    # Find contours based on Edges\n",
        "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
        "    cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:30] #sort contours based on their area\n",
        "    # keeping minimum required area as '30' (anything smaller than this will not be considered)\n",
        "    NumberPlateCnt = None #we currently have no Number plate contour\n",
        "    NewNumberPlate = []\n",
        "\n",
        "    # loop over our contours to find the best possible approximate contour of number plate\n",
        "    ROI = None\n",
        "    count = 0\n",
        "    for c in cnts:\n",
        "        peri = cv2.arcLength(c, True)\n",
        "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
        "        if len(approx) == 4:  # Select the contour with 4 corners\n",
        "            NumberPlateCnt = approx #This is our approx Number Plate Contour\n",
        "            x,y,w,h = cv2.boundingRect(c)\n",
        "            ROI = img[y:y+h, x:x+w]\n",
        "            # cv2.drawContours(image, [NumberPlateCnt], -1, (0,255,0), 3)\n",
        "            break\n",
        "    # cv2_imshow(image)\n",
        "    if NumberPlateCnt is not None:\n",
        "        for point in NumberPlateCnt:\n",
        "          NewNumberPlate.append((point * np.array([scale_x, scale_y])).tolist())\n",
        "          # NewNumberPlate.append((point).tolist())\n",
        "\n",
        "        NewNumberPlate = [[int(x[0][0]),int(x[0][1])] for x in NewNumberPlate]\n",
        "        # print(NewNumberPlate)\n",
        "        NewNumberPlate = order_edges(NewNumberPlate)\n",
        "        # cv2.circle(image_, tuple(NewNumberPlate[0]), 5, (0, 0, 255), -1) # top left\n",
        "        # cv2.circle(image_, tuple(NewNumberPlate[1]), 5, (0, 0, 255), -1) # top right\n",
        "        # cv2.circle(image_, tuple(NewNumberPlate[2]), 5, (0, 0, 255), -1) # bottom left\n",
        "        # cv2.circle(image_, tuple(NewNumberPlate[3]), 5, (0, 0, 255), -1) # bottom right\n",
        "\n",
        "        pts1 = np.float32(NewNumberPlate)\n",
        "\n",
        "        pts2 = np.float32(\n",
        "                [[0,0], # top left\n",
        "                [1000,0], # top right\n",
        "                [0,500], # bottom left\n",
        "                [1000,500]] # bottom right\n",
        "        )\n",
        "\n",
        "        matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "        result = cv2.warpPerspective(image_, matrix, (1000,500)) # set size image based on pts2 (w = 500 h = 600)\n",
        "\n",
        "        cv2.imwrite('lpoutput.jpg',result)\n",
        "        # cv2_imshow(result)\n",
        "        return result\n",
        "\n",
        "def extractNumberPlate2(img):\n",
        "    # convert input image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # read haarcascade for number plate detection\n",
        "    cascade = cv2.CascadeClassifier('/content/drive/MyDrive/Project/haarcascade_number_plate.xml')\n",
        "\n",
        "    # Detect license number plates\n",
        "    plates = cascade.detectMultiScale(gray, 1.2, 5)\n",
        "\n",
        "    # loop over all plates\n",
        "    for (x,y,w,h) in plates:\n",
        "\n",
        "        # draw bounding rectangle around the license number plate\n",
        "        cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
        "        gray_plates = gray[y:y+h, x:x+w]\n",
        "        color_plates = img[y:y+h, x:x+w]\n",
        "\n",
        "        # save number plate detected\n",
        "        cv2.imwrite('lpoutput.jpg', color_plates)\n",
        "\n",
        "def find_contours(dimensions, img) :\n",
        "\n",
        "    # Find all contours in the image\n",
        "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Retrieve potential dimensions\n",
        "    lower_width = dimensions[0]\n",
        "    upper_width = dimensions[1]\n",
        "    lower_height = dimensions[2]\n",
        "    upper_height = dimensions[3]\n",
        "\n",
        "    # Check largest 5 or  15 contours for license plate or character respectively\n",
        "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
        "\n",
        "    x_cntr_list = []\n",
        "    target_contours = []\n",
        "    img_res = []\n",
        "    for cntr in cntrs :\n",
        "        # detects contour in binary image and returns the coordinates of rectangle enclosing it\n",
        "        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n",
        "\n",
        "        # checking the dimensions of the contour to filter out the characters by contour's size\n",
        "        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :\n",
        "            x_cntr_list.append(intX) #stores the x coordinate of the character's contour, to used later for indexing the contours\n",
        "\n",
        "            char_copy = np.zeros((44,24))\n",
        "\n",
        "            # extracting each character using the enclosing rectangle's coordinates.\n",
        "            char = img[intY:intY+intHeight, intX:intX+intWidth]\n",
        "            char = cv2.resize(char, (20, 40))\n",
        "\n",
        "            cv2.rectangle(img, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n",
        "\n",
        "            # Make result formatted for classification: invert colors\n",
        "            char = cv2.subtract(255, char)\n",
        "\n",
        "            # Resize the image to 24x44 with black border\n",
        "            char_copy[2:42, 2:22] = char\n",
        "            char_copy[0:2, :] = 0\n",
        "            char_copy[:, 0:2] = 0\n",
        "            char_copy[42:44, :] = 0\n",
        "            char_copy[:, 22:24] = 0\n",
        "\n",
        "            img_res.append(char_copy) # List that stores the character's binary image (unsorted)\n",
        "\n",
        "    # arbitrary function that stores sorted list of character indeces\n",
        "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
        "    img_res_copy = []\n",
        "    for idx in indices:\n",
        "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
        "    img_res = np.array(img_res_copy)\n",
        "\n",
        "    return img_res\n",
        "\n",
        "# Find characters in the resulting images\n",
        "def segment_characters(img) :\n",
        "\n",
        "    # Preprocess cropped license plate image\n",
        "    ori_x = img.shape[1]\n",
        "    ori_y = img.shape[0]\n",
        "\n",
        "    res_x, res_y = 350, 93\n",
        "    img_lp = cv2.resize(img, (res_x, res_y))\n",
        "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
        "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
        "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
        "\n",
        "    LP_WIDTH = img_binary_lp.shape[0]\n",
        "    LP_HEIGHT = img_binary_lp.shape[1]\n",
        "\n",
        "    # Make borders white\n",
        "    img_binary_lp[0:3,:] = 255\n",
        "    img_binary_lp[:,0:3] = 255\n",
        "    img_binary_lp[res_y-3:res_y,:] = 255\n",
        "    img_binary_lp[:,res_x-3:res_x] = 255\n",
        "\n",
        "    # Estimations of character contours sizes of cropped license plates\n",
        "    dimensions = [LP_WIDTH/6,\n",
        "                       LP_WIDTH/2,\n",
        "                       LP_HEIGHT/10,\n",
        "                       2*LP_HEIGHT/3]\n",
        "    cv2.imwrite('/content/drive/My Drive/Project/contour.jpg',img_binary_lp)\n",
        "\n",
        "    # Get contours within cropped license plate\n",
        "    char_list = find_contours(dimensions, img_binary_lp)\n",
        "\n",
        "    # st.image(\"/content/drive/My Drive/Project/contour.jpg\")\n",
        "\n",
        "    return char_list\n",
        "\n",
        "def swapListElement(b):\n",
        "  d = []\n",
        "  for val in b:\n",
        "    d.append([val[1],val[0]])\n",
        "  return d\n",
        "\n",
        "def order_edges(a):\n",
        "    right_ele = heapq.nlargest(2, a)\n",
        "    swap_right_ele = swapListElement(right_ele)\n",
        "    bot_right = heapq.nlargest(2, swap_right_ele)[0]\n",
        "    top_right = heapq.nlargest(2, swap_right_ele)[1]\n",
        "    left_ele = heapq.nsmallest(2, a)\n",
        "    swap_left_ele = swapListElement(left_ele)\n",
        "    bot_left = heapq.nlargest(2, swap_left_ele)[0]\n",
        "    top_left = heapq.nlargest(2, swap_left_ele)[1]\n",
        "\n",
        "    sequenceEdges = []\n",
        "    sequenceEdges.append(top_left)\n",
        "    sequenceEdges.append(top_right)\n",
        "    sequenceEdges.append(bot_left)\n",
        "    sequenceEdges.append(bot_right)\n",
        "\n",
        "    return swapListElement(sequenceEdges)\n",
        "\n",
        "def realTime():\n",
        "    while True:\n",
        "        success, img = cap.read()\n",
        "        img = cv2.resize(img,(0,0),None,0.5,0.5)\n",
        "        ih, iw, channels = img.shape\n",
        "        blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
        "\n",
        "        # Set the input of the network\n",
        "        net.setInput(blob)\n",
        "        layersNames = net.getLayerNames()\n",
        "        outputNames = [(layersNames[i - 1]) for i in net.getUnconnectedOutLayers()]\n",
        "        # Feed data to the network\n",
        "        outputs = net.forward(outputNames)\n",
        "\n",
        "        # Find the objects from the network output\n",
        "        postProcess(outputs,img)\n",
        "\n",
        "        # Show the frames\n",
        "        # cv2_imshow(img)\n",
        "        writer.write(img)\n",
        "        cv2.imwrite(\"out.jpg\",img)\n",
        "        time.sleep(1.5)\n",
        "        clear_output()\n",
        "\n",
        "        if cv2.waitKey(1) == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Finally realese the capture object and destroy all active windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "def from_static_image(image):\n",
        "    img = cv2.imread(image)\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
        "\n",
        "    # Set the input of the network\n",
        "    net.setInput(blob)\n",
        "    layersNames = net.getLayerNames()\n",
        "    outputNames = [(layersNames[i - 1]) for i in net.getUnconnectedOutLayers()]\n",
        "    # Feed data to the network\n",
        "    outputs = net.forward(outputNames)\n",
        "\n",
        "    # Find the objects from the network output\n",
        "    postProcess(outputs,img)\n",
        "\n",
        "    # count the frequency of detected classes\n",
        "    # frequency = collections.Counter(detected_classNames)\n",
        "    # print(frequency)\n",
        "\n",
        "    # cv2_imshow(img)\n",
        "    cv2.imwrite(\"out.jpg\",img)\n",
        "\n",
        "json_file = open('/content/drive/MyDrive/Project/CharacterRecognition2/MobileNets_character_recognition.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "model.load_weights(\"/content/drive/MyDrive/Project/CharacterRecognition2/license_character_recognition.h5\")\n",
        "\n",
        "labels = LabelEncoder()\n",
        "labels.classes_ = np.load('/content/drive/MyDrive/Project/CharacterRecognition2/license_character_classes.npy')\n",
        "\n",
        "def predict_from_model(image,model,labels):\n",
        "    image = cv2.resize(image,(80,80))\n",
        "    image = np.stack((image,)*3, axis=-1)\n",
        "    prediction = labels.inverse_transform([np.argmax(model.predict(image[np.newaxis,:]))])\n",
        "    return prediction\n",
        "\n",
        "def show_results2(image):\n",
        "    char_list = segment_characters(image)\n",
        "    st.image(\"/content/drive/My Drive/Project/contour.jpg\")\n",
        "\n",
        "    final_string = ''\n",
        "    for i,character in enumerate(char_list):\n",
        "        title = np.array2string(predict_from_model(character,model,labels))\n",
        "        final_string+=title.strip(\"'[]\")\n",
        "\n",
        "    return final_string\n",
        "\n",
        "loaded_model = Sequential()\n",
        "loaded_model.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(Conv2D(32, (16,16), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(Conv2D(64, (8,8), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(Conv2D(64, (4,4), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "loaded_model.add(Dropout(0.4))\n",
        "loaded_model.add(Flatten())\n",
        "loaded_model.add(Dense(128, activation='relu'))\n",
        "loaded_model.add(Dense(36, activation='softmax'))\n",
        "\n",
        "# Restore the weights\n",
        "loaded_model.load_weights('/content/drive/My Drive/Project/CharacterRecognition/my_checkpoint')\n",
        "\n",
        "# Predicting the output\n",
        "def show_results(image):\n",
        "    dic = {}\n",
        "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "    for i,c in enumerate(characters):\n",
        "        dic[i] = c\n",
        "\n",
        "    output = []\n",
        "    char_list = segment_characters(image)\n",
        "    st.image(\"/content/drive/My Drive/Project/contour.jpg\")\n",
        "    for i,ch in enumerate(char_list): #iterating over the characters\n",
        "        img_ = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # fix dimension\n",
        "        img = np.zeros((28,28,3))\n",
        "        for i in range(3):\n",
        "          img[:,:,i] = img_\n",
        "\n",
        "        img = img.reshape(1,28,28,3) #preparing image for the model\n",
        "        # y_ = loaded_model.predict_classes(img)[0] #predicting the class (Depreciated)\n",
        "        predict = loaded_model.predict(tf.expand_dims(img[0],axis=0), verbose=0)\n",
        "        index_ = tf.argmax(predict, axis=-1).numpy()[0]\n",
        "        character = dic[index_]\n",
        "        output.append(character) #storing the result in a list\n",
        "\n",
        "    plate_number = ''.join(output)\n",
        "\n",
        "    return plate_number\n",
        "\n",
        "st.set_page_config(page_title=\"Vehicle Detection and Licence Plate Recognizer App\")\n",
        "st.title(\"Vehicle Detection and Licence Plate Recognizer\")\n",
        "st.subheader(\"Choose Image File\")\n",
        "uploaded_file = st.file_uploader(\"\", type=[\"png\", \"jpg\", \"jpeg\"], label_visibility=\"hidden\")\n",
        "\n",
        "# Check if an image file is uploaded\n",
        "if uploaded_file is not None:\n",
        "    file_details = {\"File Name\":uploaded_file.name, \"Size\":uploaded_file.size}\n",
        "    st.write(file_details)\n",
        "    with open(os.path.join(\"/content\",uploaded_file.name),\"wb\") as f:\n",
        "        f.write((uploaded_file).getbuffer())\n",
        "    # st.write(os.path.join(\"/content\",uploaded_file.name))\n",
        "    st.image(os.path.join(\"/content\",uploaded_file.name), width=500)\n",
        "    from_static_image(os.path.join(\"/content\",uploaded_file.name))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
